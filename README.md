# ðŸ•µï¸ Fake Review Detection Using Various ML Models

This project focuses on detecting fake or deceptive product reviews using multiple machine learning algorithms. It provides a practical pipeline including data preprocessing, feature engineering, model training, and evaluationâ€”all demonstrated through two structured Jupyter notebooks.

---

## ðŸ“ Project Structure
Fake-Reviews-Detection-main/
â”œâ”€â”€ Fake Reviews Detection Part-1.ipynb # Preprocessing, EDA, TF-IDF
â”œâ”€â”€ Fake Reviews Detection Part-2 Continued.ipynb # Model training & evaluation
â”œâ”€â”€ fake reviews dataset.csv # Original dataset
â”œâ”€â”€ Preprocessed Fake Reviews Detection Dataset.csv # Cleaned dataset
â””â”€â”€ README.md

---

## ðŸ“Œ Objectives

- Detect fake product reviews using ML classification.
- Preprocess text data (cleaning, tokenizing, stopword removal).
- Compare multiple ML models like Logistic Regression, SVM, Random Forest.
- Evaluate using metrics like Accuracy, Precision, Recall, F1-Score, and Confusion Matrix.

---

## ðŸ§° Tools & Libraries Used

- **Languages:** Python
- **IDE:** Jupyter Notebook
- **Libraries:**  
  - `pandas`, `numpy` â€“ Data handling  
  - `nltk`, `re` â€“ Text cleaning  
  - `scikit-learn` â€“ ML modeling and evaluation  
  - `matplotlib`, `seaborn` â€“ Visualization  

---

## ðŸ“Š ML Models Used

- Logistic Regression
- Naive Bayes
- Support Vector Machine (SVM)
- Random Forest Classifier

---

## ðŸ” Workflow Summary

1. **Part-1 Notebook:**
   - Load and explore the dataset
   - Clean text (lowercase, remove punctuation, stopwords)
   - Preprocess using TF-IDF
   - Visualizations (label distribution, word frequency)

2. **Part-2 Notebook:**
   - Train-test split
   - Apply ML models
   - Evaluate using classification metrics
   - Compare model performance

---

## ðŸ§ª Sample Evaluation Metrics

| Model               | Accuracy | Precision | Recall | F1 Score |
|--------------------|----------|-----------|--------|----------|
| Logistic Regression| ~88%     | High      | High   | Good     |
| Naive Bayes        | ~85%     | Medium    | High   | Fair     |
| SVM                | ~89%     | High      | High   | Good     |
| Random Forest      | ~91%     | High      | High   | Best     |

> *Actual results may vary based on preprocessing and data split.*

---

## ðŸ“ˆ Future Improvements

- Add Deep Learning models (LSTM, BERT).
- Use Word Embeddings instead of TF-IDF.
- Deploy as a web app (Streamlit or Flask).
- Extend to multilingual review datasets.

---

## ðŸ™Œ Author

**Gautam Kumar**  
Pre-final year B.Tech in AI & Data Science  
Email: *gk7088202@gmail.com* (optional)  


---



